# Group 08 - gOOpy

This ain't your grandma's 3D modeling software! With gOOpy you can create wild shapes and watch in fascination as they gOOp together with ray marching! Join our vibrant community of gOOpers, view their artworks, and get gOOpy today!

![Deploy](https://github.com/ubc-cpsc455-2024S/gOOpy/actions/workflows/deploy.js.yml/badge.svg)

## Goals:

## Project task requirements:

üü© - Completed
üü® - Partially
üü• - Incomplete

### minimal requirements:

-   [x] üü© Ability to add SDF primitives (spheres, boxes, etc) to the scene.
-   [x] üü© Serialize Scene Data for saving
-   [x] üü© Scene Editor / Renderer
-   [x] üü© Update the values of objects in real-time
-   [x] üü© Allows user-saved models to be retrieved on login

### ‚Äústandard‚Äù requirements:

-   [x] üü© Download image renderings
-   [x] üü© Tutorial to teach users how to user the tool
-   [x] üü© See other user‚Äôs scenes

### stretch requirements:

-   [x] üü© Strong authentication
-   [x] üü© Reactive/mobile friendly home page
-   [x] üü© Users are navigated around website in a natural way
-   [ ] üü® "Explore Page" style page
-   [ ] üü® A fleshed out materials system
-   [ ] üü• Move camera w/ controls
-   [ ] üü• User‚Äôs can like and comment on other user‚Äôs posts.
-   [ ] üü• Click and drag items to move them

## How we are using each technology

### React

We used React to build out all the client side components and logic. Everything that you can see in our project is done using react.
Below are some significant uses we had for React:

##### Editor

The editor's state and image renderer built using primarily React code. To render the scene seen on screen, our project utilizes a React frontend library called React Three Fiber which allows us to generate scenes with different shapes on a canvas. The information that allows us to create the scene is also done through React. React hooks such as useState and useEffect are used to load in previously created scene values and store changes made by our users in our sliders.

##### Main Page

The main page uses React to build out all the components. The styling of the whole page also done in a way that allows the page to be viewable on mobile as well, the logo animation is also shifted and displayed differently depending on if you're in mobile or desktop view. Here we also make use of an NPM package called React Alice Carousel which allows us to create our "Hall of Fame". The images are generated by testers of our projects and this was one way we thought we could incorporate their effort.

### Redux

We use redux to manage global state. In this project, we use redux to manage user information.
When a user logs in, we store that information and use it to display on our user page.
TODO: try to add more once we're done with more redux stuff.

### Node & Express

We use Node.js and Express to create RESTful API endpoints to handle user authentication, as well as scene saving / retrieval.

TODO I think we should say more here.

### MongoDB

We are using MongoDB to store our user data, our session data, and scene data. Our scene data contains attributes like shapes, skybox colour, skybox light colour, ambient intensity, and metadata. Shapes is a list of "shape" type, which each contain information about what type of object it is as well as other parameters to describe it's position and features.

### Github Actions & Render.com

We deployed out frontend and backend to Render.com, and set up github actions to trigger deployments. Then we set up a badge in our readme to show that the deployments are set up. This CI/CD pipeline allows our deployed webpage to always contain our most up to date changes.

## Above and Beyond Functionality

### Raymarching

The raymarching is implemented in `/gOOpy-frontend/public/shaders/raymarching.fs.glsl`.

This project uses a unique rendering technique called "raymarching". For each pixel, we cast a ray into the scene to check for collisions. Unlike raytracing which finds intersections of rays with polygons, raymarching (in our implementation) figures out the distance to the nearest shape, and then takes small steps until it hits the surface. This might sound inefficient, but it allows for some very fun new possibilities.

But how does it find the nearest distance to the surface? You can do this using a _signed distance function_. A signed distance function (or SDF) is a function that takes in an input and returns a distance to the surface. You can learn more, and see some examples [here](https://iquilezles.org/articles/distfunctions/).

So, at each step of the raymarching, we find the minimum value of all the SDFs. This gives us the maximum step size without passing through a shape. The ray will "march" to that point, and then check again. When the distance is very close to zero, we have hit a shape, and we render a surface at this point.

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Visualization_of_SDF_ray_marching_algorithm.png/2880px-Visualization_of_SDF_ray_marching_algorithm.png" width="500px">

Source: [Wikipedia](https://en.wikipedia.org/wiki/Ray_marching#/media/File:Visualization_of_SDF_ray_marching_algorithm.png)

When we render a surface, we need some more information to calculate the lighting. Specifically, the need the surface normal. This is a vector that is orthogonal to a surface. Imaging spikey hair pointing straight outwards. We can calculate this from the SDF by sampling a few nearby points and using central differences. You can learn more about this [here](https://iquilezles.org/articles/normalsSDF/).

### gOOpiness

You might be wondering what is special about raymarching and signed distance functions. Well, they allow you to do some pretty unique effects. In our case, we are using a concept called "smooth minimum". In simple terms, it finds the minimum while smoothing around the edges. This technique allows shapes to "blend" or "gOOp" together. You can read more about it [here](https://iquilezles.org/articles/smin/).

There are other cool things you can do with SDFs. For example, you could make a shape defined by the intersection of two other shapes. You can also "subtract" from a shape using another shape. These are not currently implemented in gOOpy, but we plan on implementing it some day.

### WebGL and React

There were two requirements for our Editor that needed a special solution.

1. Users can add an arbitrary number of shapes in the scene
2. Users can select multiple types of shapes in their scene

The first one was a challenge because WebGL/Three.js require that the values passed to the shader are static in size. To solve this, we simply create a large fixed-size array that we fill with our shape data. Then we only need to loop over the existing shapes withing that array. Note that WebGL requires that we fill the array with data even if it's not used.

For the second one, this is a problem that would often be solved with some type of polymorphism. However, GLSL does not support polymorphism. So instead, all of our shape objects have a "type" attribute that contains the type ID. Then the raymarching step can check a different SDF based on the type.

### Configuration and adding new shapes

There are many types of shapes that we could include in our project, but right now we only have a small subset. We created a streamlined way to add new shapes in the future.

To add a new shape:

1. Modify the raymarching shader function to include the new SDF, define the shape ID, and include it in the switch statement.
2. Modify the config file to add the shape ID, then add an entry to the shape properties array to specify how certain sliders should affect the shape data. The shape ID in the shader must match the shape ID in the config file.

The frontend will automatically pick up the new shape and it will be usable in the editor.

### Retro Vibe

We went with an intentionally retro style for our UI, such as warm colours and funky fonts. This is still a work in progress, and we intend to develop this style more over time.

### Animated logo

We created an animated logo using our rendering system. This logo is available at the `/goopy` route, if you want to see it in the renderer. However, when we use it on the main page we don't want to use the renderer for performance reasons. For this reason, we have created a webm video of the animation that we display on the homepage.

### Google login

We have implemented Google Login, allowing users to seamlessly save their scenes to their existing Google accounts.

### User flow

We have been very intentional in the design of our user flow, with the goal of lowering barriers to onboarding. We allow users to open the editor and make their scene without logging in. Then, users can click save. If they're logged in, their scene will get saved to their account. If they're not logged in, they will get redirected to the login page. After logging in, they get redirected back to the editor, which will automatically load their previous scene and save it. This is a smooth user experience to help encourage people to make accounts.

## Next Steps

We have many plans for this project, including:

1. "Explore page" allowing users to browse scenes
2. Camera movements
3. Likes and comments on scenes
4. Click and drag items to move them
5. More detailed materials system
6. Update Google login (current technique will be deprecated soon)
7. Per-shape colours
8. Improve security
9. Ability to duplicate scene
10. More SDF functions (ie intersection)
11. An in-depth, interactive tutorial

## Contributions

### Shiyu Li

I worked on setting up Express endpoints, designing MongoDB schemas and incorporating it into our project, I also implemented user session and secure login using OAuth 2.0 and worked on styling and refactoring the editor

### Aiden Kerr

I implemented the raymarching rendering and integrated it into the editor. I worked on various parts of the editor, including the shape properties configuration described above. I also worked on the deployment, some front end styling, as well as various other small things in the backend.

### Jacob Lacsamana

TODO

### Matthew Wan

My main contributions were the creating the main page, tutorial, user page, creating express endpoints and structuring our database. I designed and coded the main page, taking into account a mobile view and reactivity for resizing events. I also planned the layout and built all the frontend components in the tutorial and user pages, including working with Aiden to handle thumbnail generation which turned out
For the backend endpoints, I used mongoose to create many of the queries we use to fetch information to the user. I also setup many of the express endpoints for the users and scenes, including formatting the scene information to be saved in our MongoDB database.

## References

-   Ray Marching concepts, Nico
    -   [link](https://barradeau.com/blog/?p=575)
-   Smooth Minimum, Inigo Quilez
    -   [link](https://iquilezles.org/articles/smin/)
-   SDF Normal Vectors Calculations, Inigo Quilez
    -   [link](https://iquilezles.org/articles/normalsSDF/)
-   React help
    -   [link](https://stackoverflow.com/questions/55987953/how-do-i-update-states-onchange-in-an-array-of-object-in-react-hooks)
-   HeroIcons
    -   [link](https://heroicons.com/)
